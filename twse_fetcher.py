import httpx
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path
from dateutil.relativedelta import relativedelta
from tqdm import tqdm

def get_twse_month_data(stock_code: str, date: datetime) -> list:
    date_str = date.strftime("%Y%m01")
    url = f"https://www.twse.com.tw/exchangeReport/STOCK_DAY?response=json&date={date_str}&stockNo={stock_code}"
    # print("ğŸ“¡ æ­£åœ¨æŠ“å–ï¼š", url)

    try:
        response = httpx.get(url, timeout=10.0, verify=False)
        data = response.json()
        return data.get("data", [])
    except:
        return []

def convert_to_df(data_rows: list) -> pd.DataFrame:
    records = []
    for row in data_rows:
        try:
            roc_date = row[0].replace("/", "-")
            y, m, d = map(int, roc_date.split("-"))
            date = datetime(y + 1911, m, d).strftime("%Y-%m-%d")
            open_ = float(row[3].replace(",", ""))
            high = float(row[4].replace(",", ""))
            low = float(row[5].replace(",", ""))
            close = float(row[6].replace(",", ""))
            volume = int(row[1].replace(",", ""))
            records.append([date, open_, high, low, close, volume])
        except:
            continue
    return pd.DataFrame(records, columns=["Date", "Open", "High", "Low", "Close", "Volume"])

def fetch_twse_history(stock_code: str):
    today = datetime.today()
    file_path = Path(f"data/{stock_code}_history.csv")
    Path("data").mkdir(exist_ok=True)

    if file_path.exists():
        try:
            existing_df = pd.read_csv(file_path, parse_dates=["Date"])
            last_date = existing_df["Date"].max()
        except:
            return (stock_code, ["æ­·å²æª”æ¡ˆè®€å–å¤±æ•—"])
    else:
        existing_df = pd.DataFrame()
        last_date = today - relativedelta(months=12)

    all_data = []

    for i in range(12):
        date = today - relativedelta(months=i)
        if date < last_date.replace(day=1):
            continue
        rows = get_twse_month_data(stock_code, date)
        df_month = convert_to_df(rows)
        if df_month.empty:
            return (stock_code, [date.strftime('%Y-%m')])
        else:
            all_data.extend(rows)

    df_new = convert_to_df(all_data)
    if not df_new.empty:
        df_new["Date"] = pd.to_datetime(df_new["Date"])
        if not existing_df.empty:
            df = pd.concat([existing_df, df_new], ignore_index=True)
            df = df.drop_duplicates(subset="Date")
        else:
            df = df_new
        df = df.sort_values("Date").reset_index(drop=True)
        df.to_csv(file_path, index=False, encoding="utf-8-sig")
        return None
    else:
        return (stock_code, ["ç„¡æœ‰æ•ˆè³‡æ–™"])

def read_stock_list(file_path="stock_list.txt") -> list:
    with open(file_path, "r", encoding="utf-8") as f:
        return [line.strip() for line in f if line.strip()]

if __name__ == "__main__":
    stock_list = read_stock_list("stock_list.txt")
    skip_count = 0
    success_count = 0
    failed_summary = []

    print(f"ğŸ“¦ é–‹å§‹æŠ“å– TWSE æ­·å²è³‡æ–™ï¼ˆå…± {len(stock_list)} æª”ï¼‰...")

    for stock_code in tqdm(stock_list, desc="è™•ç†ä¸­", ncols=80):
        result = fetch_twse_history(stock_code)
        if result is None:
            success_count += 1
        else:
            skip_count += 1
            code, months = result
            failed_summary.append(f"{code}")

    print("\nğŸ“Š æŠ“å–å®Œç•¢")
    print(f"âœ… æˆåŠŸå„²å­˜ï¼š{success_count} æª”")
    print(f"âš ï¸ è³‡æ–™ä¸è¶³æœªç”¢å‡ºï¼š{skip_count} æª”")

    if failed_summary:
        print("\nğŸš« ç¼ºå°‘è³‡æ–™çš„è‚¡ç¥¨ä»£è™Ÿï¼š")
        print(" ".join(failed_summary))
