#!/usr/bin/env python3
# -*- coding: utf-8 -*-
from __future__ import annotations

import sqlite3
from dataclasses import dataclass
from typing import Dict, List, Optional

import pandas as pd
import plotly.graph_objects as go
import streamlit as st
import numpy as np  # for vs_c1 / c1 marker row
# å…¶å®ƒ import ä¹‹å¾Œ
from common.stock_loader import load_stock_list_with_names
from ui.sr_prev_high_on_heavy import scan_prev_high_on_heavy_from_df  # æˆ–ç”¨ scan_prev_high_on_heavy_all

# === ç›¤ä¸­å–åƒ¹ï¼ˆç›´æ¥ç”¨ analyze æ¨¡çµ„çš„å‡½å¼ï¼‰ ===
try:
    from analyze.analyze_price_break_conditions_dataloader import get_today_prices
except Exception:
    try:
        from analyze_price_break_conditions_dataloader import get_today_prices
    except Exception:
        get_today_prices = None  # ä»å¯ fallback åˆ° DB æœ€æ–°æ”¶ç›¤


def get_stock_name_by_id(stock_id: str) -> str:
    """
    å¾ load_stock_list_with_names() å–å¾—çš„é¡¯ç¤ºå­—ä¸²ä¸­ï¼Œæ‰¾å‡ºæŒ‡å®šä»£ç¢¼çš„åç¨±ã€‚
    é¡¯ç¤ºå­—ä¸²é€šå¸¸é•·å¾—åƒï¼š'2330 å°ç©é›»' æˆ– '1101 å°æ³¥'ã€‚
    """
    try:
        _, stock_display = load_stock_list_with_names(refresh=False)
        for s in stock_display:
            parts = s.split()
            if parts and parts[0] == stock_id:
                return " ".join(parts[1:]) if len(parts) > 1 else ""
    except Exception:
        pass
    return ""

# -----------------------------
# è³‡æ–™è¼‰å…¥ï¼ˆDBï¼‰
# -----------------------------
def load_daily(conn: sqlite3.Connection, stock_id: str, last_n: int = 270) -> pd.DataFrame:
    sql = f"""
        SELECT date, open, high, low, close, volume
        FROM twse_prices
        WHERE stock_id = ?
        ORDER BY date DESC
        LIMIT {int(last_n)}
    """
    df = pd.read_sql_query(sql, conn, params=[stock_id], parse_dates=["date"])
    df = df.dropna(subset=["open","high","low","close"])
    df = df[(df["open"]>0) & (df["high"]>0) & (df["low"]>0) & (df["close"]>0)]
    df = df.sort_values("date").reset_index(drop=True)
    df["date_label"] = df["date"].dt.strftime("%y-%m-%d")
    return df


def load_weekly(conn: sqlite3.Connection, stock_id: str, last_n: int = 52) -> pd.DataFrame:
    sql = f"""
        SELECT year_week AS key, open, high, low, close, volume
        FROM twse_prices_weekly
        WHERE stock_id = ?
        ORDER BY year_week DESC
        LIMIT {int(last_n)}
    """
    df = pd.read_sql_query(sql, conn, params=[stock_id])
    df = df.dropna(subset=["open","high","low","close"])
    df = df[(df["open"]>0) & (df["high"]>0) & (df["low"]>0) & (df["close"]>0)]
    return df.sort_values("key").reset_index(drop=True)


def load_monthly(conn: sqlite3.Connection, stock_id: str, last_n: int = 12) -> pd.DataFrame:
    sql = f"""
        SELECT year_month AS key, open, high, low, close, volume
        FROM twse_prices_monthly
        WHERE stock_id = ?
        ORDER BY year_month DESC
        LIMIT {int(last_n)}
    """
    df = pd.read_sql_query(sql, conn, params=[stock_id])
    df = df.dropna(subset=["open","high","low","close"])
    df = df[(df["open"]>0) & (df["high"]>0) & (df["low"]>0) & (df["close"]>0)]
    return df.sort_values("key").reset_index(drop=True)


def get_c1(conn: sqlite3.Connection, stock_id: str) -> float:
    row = pd.read_sql_query(
        "SELECT close FROM twse_prices WHERE stock_id=? ORDER BY date DESC LIMIT 1",
        conn, params=[stock_id]
    )
    if row.empty or pd.isna(row.iloc[0]["close"]):
        raise RuntimeError(f"æ‰¾ä¸åˆ° {stock_id} çš„æœ€æ–°æ”¶ç›¤åƒ¹ï¼ˆtwse_pricesï¼‰ã€‚")
    return float(row.iloc[0]["close"])


# -----------------------------
# é€šç”¨è³‡æ–™çµæ§‹
# -----------------------------
@dataclass
class Gap:
    timeframe: str
    gap_type: str          # "up" / "down" / "hv_red" / "hv_green" / "hv_true_red" / "hv_true_green"
    edge_price: float
    role: str              # "support" / "resistance" / "at_edge"
    ka_key: str
    kb_key: str
    gap_low: float         # å° heavy SRï¼Œ=edge_price
    gap_high: float        # å° heavy SRï¼Œ=edge_price
    gap_width: float       # å° heavy SRï¼Œ=0.0
    strength: str = "secondary"  # "primary"=ä¸€ç´šåŠ ç²—, "secondary"=ä¸€èˆ¬


def _fmt_key_for_tf(val, timeframe: str) -> str:
    if timeframe == "D":
        try:
            return pd.to_datetime(val).strftime("%Y-%m-%d")
        except Exception:
            s = str(val)
            return s[:10] if len(s) >= 10 else s
    return str(val)


# -----------------------------
# ç¼ºå£æƒæï¼ˆæ—¢æœ‰ï¼‰
# -----------------------------
def scan_gaps_from_df(df: pd.DataFrame, key_col: str, timeframe: str, c1: float) -> List[Gap]:
    out: List[Gap] = []
    if len(df) < 2:
        return out
    for i in range(1, len(df)):
        ka = df.iloc[i-1]
        kb = df.iloc[i]
        ka_low, ka_high = float(ka["low"]), float(ka["high"])
        kb_low, kb_high = float(kb["low"]), float(kb["high"])

        if ka_high < kb_low:  # up gap
            gap_low, gap_high = ka_high, kb_low
            edge, gtype = ka_high, "up"
        elif ka_low > kb_high:  # down gap
            gap_low, gap_high = kb_high, ka_low
            edge, gtype = ka_low, "down"
        else:
            continue

        role = "support" if c1 > edge else "resistance" if c1 < edge else "at_edge"
        out.append(Gap(timeframe, gtype, float(round(edge, 3)), role,
                       _fmt_key_for_tf(ka[key_col], timeframe), _fmt_key_for_tf(kb[key_col], timeframe),
                       float(round(gap_low,3)), float(round(gap_high,3)),
                       float(round(gap_high-gap_low,3))))
    return out


# =============================
# æ¨¡çµ„åŒ–ï¼šå¤§é‡ / æ¯”æ˜¨åƒ¹ / ä»Šåƒ¹ åˆ¤æ–·ï¼ˆæ–°ï¼‰
# =============================
def enrich_kbar_signals(df: pd.DataFrame,
                        ma_window: int = 20,
                        heavy_ma_multiple: float = 1.7,
                        heavy_prev_multiple: float = 1.5,
                        no_shrink_ratio: float = 0.6) -> pd.DataFrame:
    """
    å›å‚³å«ä»¥ä¸‹æ¬„ä½çš„ DataFrameï¼š
      - v_maN: è¿‘ N æ—¥å‡é‡
      - prev_volume: å‰ä¸€æ ¹é‡
      - is_heavy_ma: é‡ >= è¿‘ N æ—¥å‡é‡ * heavy_ma_multiple ä¸” é‡ >= prev_volume * no_shrink_ratio
      - is_heavy_prev: é‡ >= å‰ä¸€æ ¹ * heavy_prev_multiple
      - is_heavy: is_heavy_ma or is_heavy_prev

      - prev_close: å‰ä¸€æ ¹æ”¶ç›¤
      - up_vs_prev / down_vs_prev: æ¯”æ˜¨åƒ¹æ¼²/è·Œ
      - up_today / down_today: ä»Šåƒ¹æ¼²/è·Œ
      - is_true_red / is_true_green: çœŸç´…/çœŸç¶ ï¼ˆæ¯”æ˜¨ + ä»Šæ—¥åŒå‘ï¼‰
    """
    d = df.copy()

    # å‡é‡èˆ‡å‰ä¸€æ ¹é‡
    d["v_maN"] = d["volume"].rolling(window=ma_window, min_periods=ma_window).mean()
    d["prev_volume"] = d["volume"].shift(1)

    # æ¢ä»¶1ï¼šå‡é‡å€æ•¸ + ä¸é‡ç¸®ï¼ˆkb >= 0.6 * kaï¼‰
    cond_ma = (d["v_maN"].notna()) & (d["volume"] >= heavy_ma_multiple * d["v_maN"])
    cond_no_shrink = d["prev_volume"].notna() & (d["volume"] >= no_shrink_ratio * d["prev_volume"])
    d["is_heavy_ma"] = cond_ma & cond_no_shrink

    # æ¢ä»¶2ï¼šç›¸å°å‰ä¸€æ ¹å€æ•¸
    d["is_heavy_prev"] = d["prev_volume"].notna() & (d["volume"] >= heavy_prev_multiple * d["prev_volume"])

    # å¸¶å¤§é‡ï¼ˆä»»ä¸€æˆç«‹ï¼‰
    d["is_heavy"] = d["is_heavy_ma"] | d["is_heavy_prev"]

    # åƒ¹æ ¼é—œä¿‚
    d["prev_close"] = d["close"].shift(1)
    d["up_vs_prev"] = d["prev_close"].notna() & (d["close"] > d["prev_close"])
    d["down_vs_prev"] = d["prev_close"].notna() & (d["close"] < d["prev_close"])
    d["up_today"] = d["close"] > d["open"]
    d["down_today"] = d["close"] < d["open"]

    d["is_true_red"] = d["up_vs_prev"] & d["up_today"]
    d["is_true_green"] = d["down_vs_prev"] & d["down_today"]

    return d


# -----------------------------
# æƒ…æ³ 1ï¼šå¤§é‡ K æ£’çš„ S/Rï¼ˆæ–°ç‰ˆè¦å‰‡ï¼‰
# -----------------------------
def scan_heavy_sr_from_df(df: pd.DataFrame, key_col: str, timeframe: str, c1: float,
                          window: int = 20,
                          multiple: float = 1.7,
                          prev_multiple: float = 1.5,
                          no_shrink_ratio: float = 0.6) -> List[Gap]:
    """
    å¸¶å¤§é‡ :=
      (volume >= è¿‘20å‡é‡ * multiple ä¸” volume >= prev_volume * no_shrink_ratio)
      or (volume >= prev_volume * prev_multiple)

    å››æƒ…å¢ƒï¼ˆå‡ç‚ºå¸¶å¤§é‡å‰æï¼‰ï¼š
      a) æ¯”æ˜¨è·Œ + ä»Šè·Œ â†’ é«˜é» = ä¸€ç´šåŠ ç²— å£“åŠ›
      b) æ¯”æ˜¨æ¼² + ä»Šæ¼² â†’ ä½é» = ä¸€ç´šåŠ ç²— æ”¯æ’ï¼›é«˜é» = äºŒç´šä¸€èˆ¬ å£“åŠ› (æˆäº¤é‡æ˜¯å¤§ç´…æ£’ akaåƒ¹æ¼²é‡å¢)
      c) æ¯”æ˜¨è·Œ + ä»Šæ¼² â†’ é«˜é» = äºŒç´šä¸€èˆ¬ å£“åŠ›
      d) æ¯”æ˜¨æ¼² + ä»Šè·Œ â†’ ä½é» = äºŒç´šä¸€èˆ¬ æ”¯æ’ï¼›é«˜é» = äºŒç´šä¸€èˆ¬ å£“åŠ› (æˆäº¤é‡æ˜¯å¤§ç´…æ£’ akaåƒ¹æ¼²é‡å¢)

    é«˜é»ä¸€å¾‹è¦–ç‚ºå£“åŠ›å€™é¸ï¼ˆæœ€å¾Œä¾ c1 å‹•æ…‹è½‰æ›ï¼‰ã€‚
    """
    out: List[Gap] = []
    if df.empty:
        return out

    d = enrich_kbar_signals(
        df,
        ma_window=window,
        heavy_ma_multiple=multiple,
        heavy_prev_multiple=prev_multiple,
        no_shrink_ratio=no_shrink_ratio,
    )

    d = d[d["is_heavy"]].reset_index(drop=True)
    if d.empty:
        return out

    for _, r in d.iterrows():
        key_val = _fmt_key_for_tf(r[key_col], timeframe)

        up_vs_prev   = bool(r["up_vs_prev"])
        down_vs_prev = bool(r["down_vs_prev"])
        up_today     = bool(r["up_today"])
        down_today   = bool(r["down_today"])
        is_true_red   = bool(r["is_true_red"])
        is_true_green = bool(r["is_true_green"])

        high_p = float(r["high"])
        low_p  = float(r["low"])

        # é«˜é»ï¼šæ°¸é æ˜¯å£“åŠ›ä¾†æºï¼›ä¸€ç´šåŠ ç²— = æƒ…å¢ƒ aï¼ˆæ¯”æ˜¨è·Œï¼†ä»Šè·Œï¼‰
        high_strength = "primary" if (down_vs_prev and down_today) else "secondary"
        high_type = "hv_true_green" if is_true_green else ("hv_true_red" if is_true_red else ("hv_green" if down_today else "hv_red"))
        role_high = "support" if c1 > high_p else "resistance" if c1 < high_p else "at_edge"
        out.append(Gap(
            timeframe=timeframe,
            gap_type=high_type,
            edge_price=float(round(high_p, 3)),
            role=role_high,
            ka_key=key_val, kb_key=key_val,
            gap_low=float(round(high_p, 3)),
            gap_high=float(round(high_p, 3)),
            gap_width=0.0,
            strength=high_strength
        ))

        # ä½é»ï¼šæƒ…å¢ƒ b/d æœƒåŠ å…¥ï¼›æƒ…å¢ƒ b = ä¸€ç´šåŠ ç²—
        add_low = False
        low_strength = "secondary"
        low_type = "hv_true_red" if is_true_red else ("hv_true_green" if is_true_green else ("hv_red" if up_today else "hv_green"))

        if up_vs_prev and up_today:      # b
            add_low = True
            low_strength = "primary"
        elif up_vs_prev and down_today:  # d
            add_low = True

        if add_low:
            role_low = "support" if c1 > low_p else "resistance" if c1 < low_p else "at_edge"
            out.append(Gap(
                timeframe=timeframe,
                gap_type=low_type,
                edge_price=float(round(low_p, 3)),
                role=role_low,
                ka_key=key_val, kb_key=key_val,
                gap_low=float(round(low_p, 3)),
                gap_high=float(round(low_p, 3)),
                gap_width=0.0,
                strength=low_strength
            ))

    return out


# -----------------------------
# ç•«åœ–ï¼ˆå«æˆäº¤é‡ï¼‰
# -----------------------------
def make_chart(daily: pd.DataFrame, gaps: List[Gap], c1: float,
               show_zones: bool, show_labels: bool,
               include: Dict[str, bool],
               stock_id: str = "", stock_name: str = "") -> go.Figure:
    fig = go.Figure()

    fig.add_trace(go.Candlestick(
        x=daily["date_label"],
        open=daily["open"], high=daily["high"],
        low=daily["low"], close=daily["close"],
        name="Daily",
        increasing_line_color="red", increasing_fillcolor="red",
        decreasing_line_color="green", decreasing_fillcolor="green",
        yaxis="y1"
    ))

    fig.add_trace(go.Bar(
        x=daily["date_label"],
        y=daily["volume"],                     # DB æ˜¯è‚¡
        name="Volume",
        marker=dict(color="rgba(128,128,128,0.35)"),
        yaxis="y2",
        customdata=(daily["volume"] / 1000.0), # è½‰å¼µæ•¸çµ¦ hover
        hovertemplate="Volume: %{customdata:,.0f} å¼µ<extra></extra>"
    ))

    fig.add_hline(
        y=c1, line_color="black", line_width=2, line_dash="dash",
        annotation_text=f"{stock_id} {stock_name}  c1 {c1:.2f}",
        annotation_position="top left"
    )

    zone_color = {"D": "rgba(66,135,245,0.18)", "W": "rgba(255,165,0,0.18)", "M": "rgba(46,204,113,0.18)"}
    line_color_role = {"support": "#16a34a", "resistance": "#dc2626", "at_edge": "#737373"}
    line_width_tf = {"D": 1.2, "W": 1.8, "M": 2.4}
    strength_mul = {"primary": 1.8, "secondary": 1.0}
    dash_role = {"support": "dot", "resistance": "solid", "at_edge": "dash"}

    for g in gaps:
        if not include.get(g.timeframe, True):
            continue
        if show_zones and (g.gap_high > g.gap_low):
            fig.add_hrect(y0=g.gap_low, y1=g.gap_high, line_width=0,
                          fillcolor=zone_color[g.timeframe], opacity=0.25, layer="below")

        base_w = line_width_tf[g.timeframe]
        lw = base_w * strength_mul.get(getattr(g, "strength", "secondary"), 1.0)

        fig.add_hline(y=g.edge_price, line_color=line_color_role[g.role],
                      line_width=lw, line_dash=dash_role[g.role])

        if show_labels:
            label_src = "HV" if g.gap_type.startswith("hv_") else g.gap_type
            fig.add_annotation(xref="paper", x=0.995, xanchor="right",
                               y=g.edge_price, yanchor="middle",
                               text=f"{g.timeframe} {label_src} {g.role} {g.edge_price} ({g.kb_key})",
                               showarrow=False, font=dict(size=10, color=line_color_role[g.role]),
                               bgcolor="rgba(255,255,255,0.6)", bordercolor="rgba(0,0,0,0.2)")

    fig.update_xaxes(type="category")
    fig.update_layout(
        xaxis=dict(domain=[0, 1]),
        yaxis=dict(title="Price", side="left", showgrid=True, position=0.0),
        yaxis2=dict(title="Volume", side="right", overlaying="y", showgrid=False, position=1.0),
        xaxis_rangeslider_visible=True,
        margin=dict(l=40, r=40, t=40, b=40),
        height=820,
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="left", x=0)
    )
    return fig


# -----------------------------
# ç›¤ä¸­è³‡æ–™ä½µå…¥æ—¥K / å‹•æ…‹èšåˆ
# -----------------------------
def _safe_float(d: dict, key: str, default=None):
    try:
        v = d.get(key, None)
        return float(v) if v is not None else default
    except Exception:
        return default


def attach_intraday_to_daily(daily: pd.DataFrame, today: dict) -> pd.DataFrame:
    if daily.empty or not today:
        return daily

    t_date_str = str(today.get("date") or "")
    if not t_date_str:
        return daily

    t_date = pd.to_datetime(t_date_str).normalize()
    o   = _safe_float(today, "o")
    h   = _safe_float(today, "h")
    l   = _safe_float(today, "l")
    c1  = _safe_float(today, "c1")
    v   = _safe_float(today, "v", default=0.0)

    # ç›¤ä¸­ v å–®ä½æ˜¯å¼µ -> è½‰è‚¡
    if v is not None: v = float(v) * 1000.0

    row_today = {
        "date": t_date, "open": o, "high": h, "low": l, "close": c1,
        "volume": v, "date_label": t_date.strftime("%y-%m-%d"),
    }

    df = daily.copy()
    mask = (df["date"].dt.normalize() == t_date)
    if mask.any():
        idx = df.index[mask][-1]
        for k, vv in row_today.items():
            df.at[idx, k] = vv
    else:
        df = pd.concat([df, pd.DataFrame([row_today])], ignore_index=True)

    return df.sort_values("date").reset_index(drop=True)


def aggregate_weekly_from_daily(daily_with_today: pd.DataFrame, last_n: int = 52) -> pd.DataFrame:
    if daily_with_today.empty:
        return pd.DataFrame(columns=["key", "open", "high", "low", "close", "volume"])
    df = daily_with_today.copy()
    df["date"] = pd.to_datetime(df["date"])
    iso = df["date"].dt.isocalendar()
    df["year_week"] = iso.year.astype(str) + "-" + iso.week.map(lambda x: f"{int(x):02d}")
    wk = (
        df.sort_values("date")
          .groupby("year_week", as_index=False)
          .agg(open=("open", "first"), high=("high", "max"),
               low=("low", "min"), close=("close", "last"),
               volume=("volume", "sum"))
          .rename(columns={"year_week": "key"})
          .sort_values("key")
          .reset_index(drop=True)
    )
    if last_n is not None:
        wk = wk.tail(int(last_n)).reset_index(drop=True)
    return wk


def aggregate_monthly_from_daily(daily_with_today: pd.DataFrame, last_n: int = 12) -> pd.DataFrame:
    if daily_with_today.empty:
        return pd.DataFrame(columns=["key", "open", "high", "low", "close", "volume"])
    df = daily_with_today.copy()
    df["date"] = pd.to_datetime(df["date"])
    df["year_month"] = df["date"].dt.strftime("%Y-%m")
    mk = (
        df.sort_values("date")
          .groupby("year_month", as_index=False)
          .agg(open=("open", "first"), high=("high", "max"),
               low=("low", "min"), close=("close", "last"),
               volume=("volume", "sum"))
          .rename(columns={"year_month": "key"})
          .sort_values("key")
          .reset_index(drop=True)
    )
    if last_n is not None:
        mk = mk.tail(int(last_n)).reset_index(drop=True)
    return mk


# -----------------------------
# ä¸»ç¨‹å¼
# -----------------------------
def main() -> None:
    st.set_page_config(page_title="S/R æ’å£“ç³»çµ± (D/W/M)", layout="wide")
    st.title("this is money -> æ”¯æ’ / å£“åŠ›ï¼ˆD / W / Mï¼‰")

    st.markdown(
        """
        <style>
        [data-testid="stSidebar"][aria-expanded="true"]{
            min-width: 200px !important;
            max-width: 220px !important;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

    with st.sidebar:
        st.subheader("è¨­å®š")
        # stock_id = st.text_input("è‚¡ç¥¨ä»£ç¢¼ï¼ˆä¾‹ï¼š2330ï¼‰", value="2330")
        # ç”¨ on_change æ¨¡æ“¬æäº¤ï¼Œç„¶å¾Œè‡ªå‹•æ¸…ç©º
        def submit_stock_id():
            st.session_state["submitted_stock_id"] = st.session_state["stock_id_input"]
            st.session_state["stock_id_input"] = ""  # æ¸…ç©ºè¼¸å…¥æ¡†

        st.text_input(
            "è‚¡ç¥¨ä»£ç¢¼ï¼ˆä¾‹ï¼š2330ï¼‰",
            key="stock_id_input",
            placeholder="ä¾‹å¦‚ï¼š2330",
            on_change=submit_stock_id
        )

        # ä½¿ç”¨è€…è¼¸å…¥å®ŒæˆæŒ‰ Enter â†’ submit_stock_id è¢«å‘¼å«
        stock_id = st.session_state.get("submitted_stock_id", "").strip()

        last_days = st.number_input("æ—¥K é¡¯ç¤ºå¤©æ•¸", min_value=60, max_value=720, value=120, step=30)

        st.markdown("---")
        st.caption("å¸¶å¤§é‡åˆ¤æ–·åƒæ•¸")
        hv_ma_mult = st.number_input("è¿‘20æ—¥å‡é‡å€æ•¸ï¼ˆæ¢ä»¶1ï¼‰", min_value=1.0, max_value=5.0, value=1.7, step=0.1)
        no_shrink_ratio = st.number_input("ä¸é‡ç¸®ä¸‹é™ï¼ˆkb >= ka Ã— ?ï¼‰", min_value=0.1, max_value=1.0, value=0.6, step=0.05)
        hv_prev_mult = st.number_input("ç›¸å°å‰ä¸€æ ¹å€æ•¸ï¼ˆæ¢ä»¶2ï¼‰", min_value=1.0, max_value=5.0, value=1.2, step=0.1)

        st.markdown("---")
        st.caption("Pivot High åƒæ•¸è¨­å®š")
        d_pivot_left = st.number_input("æ—¥K pivot_left", min_value=1, max_value=10, value=3, step=1)
        d_pivot_right = st.number_input("æ—¥K pivot_right", min_value=1, max_value=10, value=3, step=1)
        w_pivot_left = st.number_input("é€±K pivot_left", min_value=1, max_value=10, value=2, step=1)
        w_pivot_right = st.number_input("é€±K pivot_right", min_value=1, max_value=10, value=2, step=1)
        m_pivot_left = st.number_input("æœˆK pivot_left", min_value=1, max_value=10, value=1, step=1)
        m_pivot_right = st.number_input("æœˆK pivot_right", min_value=1, max_value=10, value=1, step=1)

        st.markdown("---")
        st.caption("é¡¯ç¤ºå“ªç¨®æ™‚é–“æ¡†æ¶çš„ç¼ºå£")
        inc_d = st.checkbox("æ—¥ç·š (D)", value=True)
        inc_w = st.checkbox("é€±ç·š (W)", value=True)
        inc_m = st.checkbox("æœˆç·š (M)", value=True)

        st.markdown("---")
        c1_override = st.text_input("c1 è¦†å¯«ï¼ˆé€šå¸¸ç•™ç©ºï¼›åƒ…ä¾›æ¸¬è©¦/æ¨¡æ“¬ï¼‰", value="")
        c1_val: Optional[float] = float(c1_override) if c1_override.strip() else None
        db_path = st.text_input("SQLite DB è·¯å¾‘", value="data/institution.db")

        show_zones = st.checkbox("é¡¯ç¤ºç¼ºå£å€é–“ (hrect)", value=False)
        show_labels = st.checkbox("é¡¯ç¤ºé‚Šç•Œæ¨™ç±¤ (edge labels)", value=False)


    stock_name = get_stock_name_by_id(stock_id)

    from pathlib import Path

    COVER_CANDIDATES = [
        "support-and-resistance-cover-image.png",
        "data/images/support-and-resistance-cover-image.png",
    ]
    cover_img = next((p for p in COVER_CANDIDATES if Path(p).exists()), None)

    if not stock_id:
        if cover_img:
            st.image(cover_img, use_container_width=True)
        else:
            st.info("è«‹åœ¨å·¦å´è¼¸å…¥è‚¡ç¥¨ä»£ç¢¼ï¼ˆä¾‹ï¼š2330ï¼‰")
        st.stop()  # ç›´æ¥ä¸­æ­¢ï¼Œä¸è¦é€²å…¥æŸ¥è³‡æ–™èˆ‡ç•«åœ–


    conn = sqlite3.connect(db_path)
    try:
        daily = load_daily(conn, stock_id, last_n=int(last_days))
        if daily.empty:
            st.error("æŸ¥ç„¡æ—¥Kè³‡æ–™ã€‚"); return

        today_info = None
        if get_today_prices is not None:
            try:
                today_info = get_today_prices(stock_id, sdk=None)
            except Exception:
                today_info = None

        if c1_val is not None:
            c1 = c1_val
        elif today_info and ("c1" in today_info):
            c1 = float(today_info["c1"])
        else:
            c1 = get_c1(conn, stock_id)

        daily_with_today = attach_intraday_to_daily(daily, today_info or {})
        wk = aggregate_weekly_from_daily(daily_with_today, last_n=52)
        mo = aggregate_monthly_from_daily(daily_with_today, last_n=12)

        # === å»ºç«‹ year-week â†’ è©²é€±ç¬¬ä¸€å€‹äº¤æ˜“æ—¥(MM-DD) çš„å°ç…§ï¼ˆä¾›è¡¨æ ¼å‹å–„é¡¯ç¤ºï¼‰ ===
        week_first_day_map = {}
        if not daily_with_today.empty:
            _t = daily_with_today.copy()
            iso = _t["date"].dt.isocalendar()
            _t["year_week"] = iso.year.astype(str) + "-" + iso.week.map(lambda x: f"{int(x):02d}")
            week_first_day_map = (
                _t.groupby("year_week", as_index=True)["date"]
                .min()                         # è©²é€±ç¬¬ä¸€å€‹ã€Œäº¤æ˜“æ—¥ã€
                .dt.strftime("%m-%d")          # åªé¡¯ç¤ºæœˆ-æ—¥
                .to_dict()
            )

        def _augment_week_key(val: str) -> str:
            """æŠŠ 'YYYY-WW' è®Šæˆ 'YYYY-WW (MM-DD)'ï¼›éé€±æ ¼å¼æˆ–æŸ¥ä¸åˆ°å°±åŸæ¨£è¿”å›ã€‚"""
            try:
                if isinstance(val, str) and val in week_first_day_map:
                    return f"{val} ({week_first_day_map[val]})"
            except Exception:
                pass
            return val


        d_gaps = scan_gaps_from_df(daily_with_today.rename(columns={"date": "key"}), key_col="key", timeframe="D", c1=c1)
        w_gaps = scan_gaps_from_df(wk, key_col="key", timeframe="W", c1=c1)
        m_gaps = scan_gaps_from_df(mo, key_col="key", timeframe="M", c1=c1)

        d_hv = scan_heavy_sr_from_df(
            daily_with_today.rename(columns={"date": "key"}), key_col="key", timeframe="D", c1=c1,
            window=20, multiple=hv_ma_mult, prev_multiple=hv_prev_mult, no_shrink_ratio=no_shrink_ratio
        )
        w_hv = scan_heavy_sr_from_df(
            wk, key_col="key", timeframe="W", c1=c1,
            window=20, multiple=hv_ma_mult, prev_multiple=hv_prev_mult, no_shrink_ratio=no_shrink_ratio
        )
        m_hv = scan_heavy_sr_from_df(
            mo, key_col="key", timeframe="M", c1=c1,
            window=20, multiple=hv_ma_mult, prev_multiple=hv_prev_mult, no_shrink_ratio=no_shrink_ratio
        )


        # æ—¢æœ‰ï¼šç¼ºå£ & å¤§é‡Kæ£’ S/R éƒ½ç®—å®Œäº†
        # d_gaps, w_gaps, m_gaps å·²å°±ç·’
        # d_hv, w_hv, m_hv å·²å°±ç·’

        # === æ–°å¢ï¼šæ—¥ / é€± / æœˆ çš„ã€Œå¸¶å¤§é‡å‰æ³¢é«˜ã€ ===
        d_prev = scan_prev_high_on_heavy_from_df(
            daily_with_today.rename(columns={"date": "key"}), key_col="key", timeframe="D", c1=c1,
            window=20, multiple=hv_ma_mult, prev_multiple=hv_prev_mult, no_shrink_ratio=no_shrink_ratio,
            pivot_left=d_pivot_left, pivot_right=d_pivot_right, max_lookback=120, pivot_heavy_only=True
        )
        w_prev = scan_prev_high_on_heavy_from_df(
            wk, key_col="key", timeframe="W", c1=c1,
            window=20, multiple=hv_ma_mult, prev_multiple=hv_prev_mult, no_shrink_ratio=no_shrink_ratio,
            pivot_left=w_pivot_left, pivot_right=w_pivot_right, max_lookback=60, pivot_heavy_only=True
        )
        m_prev = scan_prev_high_on_heavy_from_df(
            mo, key_col="key", timeframe="M", c1=c1,
            window=20, multiple=hv_ma_mult, prev_multiple=hv_prev_mult, no_shrink_ratio=no_shrink_ratio,
            pivot_left=m_pivot_left, pivot_right=m_pivot_right, max_lookback=36, pivot_heavy_only=True
        )

        # === ä¿®æ”¹ï¼šæŠŠä¸‰å€‹å‰æ³¢é«˜çš„çµæœä½µé€² gaps ===
        gaps = d_gaps + w_gaps + m_gaps + d_hv + w_hv + m_hv + d_prev + w_prev + m_prev


        fig = make_chart(
            daily_with_today, gaps, c1, show_zones, show_labels,
            include={"D": inc_d, "W": inc_w, "M": inc_m},
            stock_id=stock_id, stock_name=stock_name
        )

        st.plotly_chart(fig, use_container_width=True)

        # ===============================
        # ç¼ºå£ / å¤§é‡ SR æ¸…å–® + æ’åºæç¤º
        # ===============================
        df_out = pd.DataFrame([g.__dict__ for g in gaps])
        if not df_out.empty:
            # âœ… å…ˆä¿ç•™ä¸€ä»½åŸå§‹ï¼ˆå« Pivot Highï¼‰çµ¦å°ˆå€ç”¨
            df_prev_source = df_out.copy()

            # â¬‡ï¸ ç¼ºå£æ¸…å–®è¦ä¹¾æ·¨ â†’ éæ¿¾æ‰å¸¶é‡å‰æ³¢é«˜
            df_out = df_out[df_out["gap_type"] != "hv_prev_high"].copy()

            role_rank = {"resistance": 0, "at_edge": 1, "support": 2}
            tf_rank   = {"M": 0, "W": 1, "D": 2}
            df_out["role_rank"] = df_out["role"].map(role_rank)
            df_out["tf_rank"]   = df_out["timeframe"].map(tf_rank)

            df_out = df_out.sort_values(["role_rank", "edge_price", "tf_rank"],
                                        ascending=[True, False, True]).reset_index(drop=True)

            # æ›´ç²—ã€æ›´æ¸…æ¥šçš„æ–¹å‘ç¬¦è™Ÿ
            df_out.insert(0, "vs_c1", np.where(df_out["edge_price"] > c1, "â–²",
                                np.where(df_out["edge_price"] < c1, "â–¼", "â—")))

            # âš ï¸ æ³¨æ„ï¼šé€™è£¡ä¸ç”¨å†æ¨™è¨» "Pivot High"ï¼Œå› ç‚ºå·²ç¶“ç¨ç«‹åˆ°å°ˆå€äº†

            # æ’å…¥ã€Œc1 åˆ†éš”åˆ—ã€ä¸¦é‡æ–°æ’åºåˆ°æ­£ç¢ºä½ç½®
            marker_row = {
                "timeframe":"â€”","gap_type":"â€”","edge_price":c1,"role":"at_edge",
                "ka_key":"â€”","kb_key":"â€”","gap_low":c1,"gap_high":c1,"gap_width":0.0,
                "vs_c1":"ğŸ”¶ c1","role_rank":role_rank["at_edge"],"tf_rank":1,
            }
            df_out = pd.concat([df_out, pd.DataFrame([marker_row])], ignore_index=True)
            df_out = df_out.sort_values(["role_rank","edge_price","tf_rank"],
                                        ascending=[True,False,True]).reset_index(drop=True)

            
            # â¬‡ï¸ æ–°å¢ï¼šæŠŠæ‰€æœ‰æç¤ºæ”¶ç´é€² expander
            with st.expander("ğŸ“Œ æç¤º / è¦å‰‡èªªæ˜", expanded=False):
                st.markdown(f"""
            - æ–¼æ”¯æ’ä½è²·é€²ï¼Œæ–¼å£“åŠ›ä½è³£å‡º  -> é©ç”¨æ–¼**ç›¤æ•´ç›¤**ï¼Œå› ç‚ºæ²’æœ‰å‡ºè¶¨å‹¢ï¼Œæ‰€ä»¥é‡å£“åŠ›(é«˜æ©Ÿç‡)ä¸æœƒçªç ´ï¼Œé‡æ”¯æ’é«˜æ©Ÿç‡ä¸æœƒè·Œç ´ï¼ŒçŸ­é€²çŸ­å‡ºã€‚
            - å³å´äº¤æ˜“é©ç”¨æ–¼**è¶¨å‹¢ç›¤**ï¼Œè¿½é«˜æ˜¯å› ç‚ºæ­£åœ¨ä¸Šæ¼²çš„è¶¨å‹¢ä»åœ¨(å¸¶å¤§é‡ç ´å£“è²·)ï¼Œä½æ¥æ˜¯å› ç‚ºå·²ç¶“æ­¢è·Œ(å¸¶å¤§é‡ç ´æ’ä¹‹å¾Œ3å¤©é‡ç¸®)ä¸‹è·Œè¶¨å‹¢çµæŸ)
            ---
            - **æ’åºè¦å‰‡**ï¼šè§’è‰²ï¼ˆå£“åŠ› â†’ äº¤ç•Œ â†’ æ”¯æ’ï¼‰ â†’ åƒ¹ä½ï¼ˆå¤§ â†’ å°ï¼‰ â†’ æ™‚é–“æ¡†æ¶ï¼ˆæœˆ â†’ é€± â†’ æ—¥ï¼‰ã€‚
            - **å¸¶å¤§é‡è¦å‰‡**ï¼ˆæ»¿è¶³å…¶ä¸€å³è¦–ç‚ºå¸¶å¤§é‡ï¼‰ï¼š
                - æ¢ä»¶â‘ ï¼ˆå‡é‡å€æ•¸ + ä¸é‡ç¸®ï¼‰ï¼š`volume â‰¥ è¿‘20æ—¥å‡é‡ Ã— {hv_ma_mult:.2f}` ä¸” `volume â‰¥ å‰ä¸€æ ¹ Ã— {no_shrink_ratio:.2f}`  
                ï¼ˆå°æ‡‰æ¬„ä½ï¼š`is_heavy_ma`ï¼‰
                - æ¢ä»¶â‘¡ï¼ˆç›¸å°å‰ä¸€æ ¹å€æ•¸ï¼‰ï¼š`volume â‰¥ å‰ä¸€æ ¹ Ã— {hv_prev_mult:.2f}`  
                ï¼ˆå°æ‡‰æ¬„ä½ï¼š`is_heavy_prev`ï¼‰
            - **å¸¶é‡å‰æ³¢é«˜ï¼ˆhv_prev_highï¼‰**ï¼š
                - å‰æ³¢é«˜ = **pivot high ä¸”è©² K æ£’æœ¬èº«å¸¶å¤§é‡**ï¼ˆ`pivot_heavy_only=True`ï¼‰ã€‚
                - å¾ŒçºŒå†æ¬¡å‡ºç¾**å¸¶å¤§é‡ K æ£’**æ™‚è§¸ç™¼å•Ÿç”¨æ­¤ç·šï¼ˆ`kb_key`=è§¸ç™¼æ—¥æœŸï¼›`ka_key`=å‰æ³¢é«˜æ—¥æœŸï¼‰ã€‚
            - å…¶ä»–ï¼š
                - `vs_c1` æ¬„ä½è‹¥æ¨™ç¤º **â€œPivot Highâ€**ï¼Œä»£è¡¨æ­¤åˆ—ç‚ºã€Œå¸¶é‡å‰æ³¢é«˜ã€ã€‚
                """)

            # åŸæœ¬é€™è¡Œå¯ä»¥åˆªæ‰æˆ–ä¿ç•™åœ¨ expander åº•ä¸‹
            # st.caption("æ’åºè¦å‰‡ï¼šè§’è‰²ï¼ˆå£“åŠ›â†’äº¤ç•Œâ†’æ”¯æ’ï¼‰ â†’ åƒ¹ä½ï¼ˆå¤§â†’å°ï¼‰ â†’ æ™‚é–“æ¡†æ¶ï¼ˆæœˆâ†’é€±â†’æ—¥ï¼‰")
            st.markdown(f"**{stock_id} {stock_name}ï½œç¾åƒ¹ c1: {c1:.2f}**")
            st.subheader("ç¼ºå£ & å¤§é‡Kæ£’ S/R")
            

            cols_order = ["vs_c1","timeframe","gap_type","edge_price","role",
                          "ka_key","kb_key","gap_low","gap_high","gap_width"]
            show_df = df_out[[c for c in cols_order if c in df_out.columns]].copy()

            # é€±Kéµå€¼ç¾åŒ–ï¼š'YYYY-WW' -> 'YYYY-WW (MM-DD)'ï¼ˆæ—¥/æœˆç¶­æŒåŸæ¨£ï¼‰
            if "ka_key" in show_df.columns:
                show_df["ka_key"] = show_df["ka_key"].apply(_augment_week_key)
            if "kb_key" in show_df.columns:
                show_df["kb_key"] = show_df["kb_key"].apply(_augment_week_key)


            # é¡¯ç¤ºåˆ°å°æ•¸å¾Œå…©ä½ï¼ˆç”¨ Styler.format æ§åˆ¶æ¸²æŸ“ç²¾åº¦ï¼‰
            num_cols = [c for c in ["edge_price","gap_low","gap_high","gap_width"] if c in show_df.columns]
            fmt_map = {c: "{:.2f}" for c in num_cols}

            # åªé‡å° gap_type æ¬„ä½ä¸Šè‰²ï¼ˆæ“´å……ï¼šåŒ…å« hv_true_*ï¼‰
            def highlight_gap_type(val: str) -> str:
                v = str(val)
                if v in ("hv_green","hv_true_green"):
                    return "background-color: #e6f4ea"   # æ·¡ç¶ 
                if v in ("hv_red","hv_true_red"):
                    return "background-color: #fdecea"   # æ·¡ç´…
                return ""

            # c1 é«˜äº®ï¼šæ•´åˆ—æ·¡é»ƒ + ç²—é«”
            def highlight_c1_row(row):
                is_marker = (str(row.get("vs_c1","")) == "ğŸ”¶ c1")
                same_price = False
                try:
                    same_price = float(row["edge_price"]) == float(c1)
                except Exception:
                    pass
                if is_marker or same_price:
                    return ["background-color: #fff3cd; font-weight: bold"] * len(row)
                return [""] * len(row)

            styled = (
                show_df
                    .style
                    .format(fmt_map)                                 # æ•¸å­—å…©ä½å°æ•¸
                    .apply(highlight_c1_row, axis=1)                 # å…ˆå¥—æ•´åˆ— c1 é«˜äº®
                    .map(highlight_gap_type, subset=["gap_type"])    # åªçµ¦ gap_type æ¬„ä½ä¸Šè‰²
            )

            st.dataframe(styled, height=360, use_container_width=True)

            # ===============================
            # â‘¡ å¸¶é‡å‰æ³¢é«˜ã€Œå°ˆå€ã€è¡¨æ ¼ï¼ˆç¨ç«‹ï¼‰
            # ===============================
            st.markdown("---")
            st.subheader("å¸¶é‡å‰æ³¢é«˜ Pivot High")

            # ç”¨ df_prev_sourceï¼Œè€Œä¸æ˜¯ df_out
            df_prev = df_prev_source[df_prev_source["gap_type"] == "hv_prev_high"].copy()

            if df_prev.empty:
                st.info("æ­¤ç¯„åœå…§æ²’æœ‰åµæ¸¬åˆ°ã€å¸¶é‡å‰æ³¢é«˜ã€ã€‚")
            else:
                # è§’è‰²èˆ‡æ™‚é–“æ¡†æ¶æ’åºæ¬Šé‡ï¼ˆæ™‚é–“æ¡†æ¶ï¼šæœˆâ†’é€±â†’æ—¥ï¼‰
                role_rank_ph = {"resistance": 0, "at_edge": 1, "support": 2}
                tf_rank_ph   = {"M": 0, "W": 1, "D": 2}

                # æ’åºéµï¼šæ™‚é–“æ¡†æ¶ï¼ˆæœˆâ†’é€±â†’æ—¥ï¼‰ â†’ ka_key(å¤§åˆ°å°) â†’ è§’è‰²ï¼ˆå£“åŠ›â†’äº¤ç•Œâ†’æ”¯æ’ï¼‰ â†’ åƒ¹ä½ï¼ˆå¤§â†’å°ï¼‰
                # ka_key éƒ½æ˜¯å­—ä¸²ï¼ˆD:YYYY-MM-DD / W:YYYY-WW / M:YYYY-MMï¼‰ï¼Œå­—ä¸²å€’åºèˆ‡æ™‚é–“å€’åºä¸€è‡´
                df_prev["tf_rank_ph"]   = df_prev["timeframe"].map(tf_rank_ph)
                df_prev["role_rank_ph"] = df_prev["role"].map(role_rank_ph)

                # å…ˆæ’å…¥ c1 æ¨™è¨˜åˆ—ï¼ˆå’Œç¬¬ä¸€å¼µè¡¨ä¸€è‡´ï¼‰
                marker_row_ph = {
                    "timeframe":"â€”","gap_type":"â€”","edge_price":c1,"role":"at_edge",
                    "ka_key":"â€”","kb_key":"â€”","gap_low":c1,"gap_high":c1,"gap_width":0.0,
                    "vs_c1":"ğŸ”¶ c1","tf_rank_ph":tf_rank_ph["W"],"role_rank_ph":role_rank_ph["at_edge"],
                }
                df_prev = pd.concat([df_prev, pd.DataFrame([marker_row_ph])], ignore_index=True)

                # æ–¹å‘ç¬¦è™Ÿï¼šç¶­æŒèˆ‡ä¸»è¡¨ä¸€è‡´ï¼›ä¸¦åŠ ä¸Š Pivot High æ¨™è¨˜å­—æ¨£
                df_prev["vs_c1"] = np.where(df_prev["edge_price"] > c1, "â–²",
                                    np.where(df_prev["edge_price"] < c1, "â–¼", "â—"))
                mask_prev2 = (df_prev["gap_type"] == "hv_prev_high")
                df_prev.loc[mask_prev2, "vs_c1"] = df_prev.loc[mask_prev2, "vs_c1"] + " Pivot High"

                # ä¾è¦å‰‡æ’åºï¼ˆæ³¨æ„ ka_key ä»¥å­—ä¸²å€’åºé”æˆã€Œå¤§åˆ°å°ã€ï¼‰
                df_prev = df_prev.sort_values(
                    by=["tf_rank_ph", "ka_key", "role_rank_ph", "edge_price"],
                    ascending=[True, False, True, False]
                ).reset_index(drop=True)

                # æ¬„ä½é¡¯ç¤ºï¼ˆæŠŠ ka_key/kb_key æ”¹åï¼Œé¿å…èª¤æœƒï¼‰
                cols_prev = ["vs_c1","timeframe","edge_price","role","ka_key","kb_key","gap_low","gap_high","gap_width"]
                show_prev = df_prev[[c for c in cols_prev if c in df_prev.columns]].copy()
                show_prev = show_prev.rename(columns={"ka_key":"pivot_key", "kb_key":"trigger_key"})

                # é€±Kéµå€¼ç¾åŒ–ï¼š'YYYY-WW' -> 'YYYY-WW (MM-DD)'
                if "pivot_key" in show_prev.columns:
                    show_prev["pivot_key"] = show_prev["pivot_key"].apply(_augment_week_key)
                if "trigger_key" in show_prev.columns:
                    show_prev["trigger_key"] = show_prev["trigger_key"].apply(_augment_week_key)


                # æ¨£å¼ï¼šc1 é»ƒåº•ã€æ•¸å­—å…©ä½å°æ•¸
                num_cols_prev = [c for c in ["edge_price","gap_low","gap_high","gap_width"] if c in show_prev.columns]
                fmt_map_prev = {c: "{:.2f}" for c in num_cols_prev}

                def highlight_c1_row_prev(row):
                    is_marker = (str(row.get("vs_c1","")) == "ğŸ”¶ c1")
                    same_price = False
                    try:
                        same_price = float(row["edge_price"]) == float(c1)
                    except Exception:
                        pass
                    if is_marker or same_price:
                        return ["background-color: #fff3cd; font-weight: bold"] * len(row)
                    return [""] * len(row)

                styled_prev = (
                    show_prev
                        .style
                        .format(fmt_map_prev)
                        .apply(highlight_c1_row_prev, axis=1)
                )

                # é¡¯ç¤ºç¬¬äºŒå¼µè¡¨ï¼ˆé«˜åº¦ä½ å¯å†èª¿ï¼‰
                st.dataframe(styled_prev, height=260, use_container_width=True)


        else:
            st.info("æ­¤ç¯„åœå…§æœªåµæ¸¬åˆ°ç¼ºå£æˆ–å¤§é‡ K æ£’ S/Rã€‚")
    finally:
        conn.close()


if __name__ == "__main__":
    main()
